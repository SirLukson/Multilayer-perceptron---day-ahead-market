# -*- coding: utf-8 -*-
"""MLP_price_prediction_IOB_proj16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YmxCHZWVrvOxxuPP6OTNT6Mk0ADFUj0M
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

col_list = ["TS_UTC", "FIXING_1"]
data = pd.read_csv('rdn_csv.csv',sep=';',usecols=col_list,parse_dates=['TS_UTC'])
data.head()
df_price = data[['TS_UTC','FIXING_1']]
df_price['FIXING_1'] = df_price['FIXING_1'].str.replace('zł', '')
df_price['FIXING_1'] = df_price['FIXING_1'].str.replace(' ', '')
df_price['FIXING_1'] = df_price['FIXING_1'].str.replace(',', '.')
df_price = df_price.set_index('TS_UTC')
df_price.index = pd.to_datetime(df_price.index)
print ('Wycinek danych')
df_price["FIXING_1"] = df_price["FIXING_1"].astype(float)
print (df_price.head(3))
ax = df_price[2:25].plot(figsize=(40,16))
ax.set_xlabel('data')
ax.set_ylabel('cena w zł')

#Skalowanie cen od 0 do 1
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_price['scale'] = scaler.fit_transform(df_price['FIXING_1'].values.reshape(-1,1))
df_price['scale'].head()
ax = df_price.plot(y='scale',figsize=(40,16))
ax.set_xlabel('Data')
ax.set_ylabel('Cena w zł (przeskalowana)')

#Tworzenie zbioru danych
def create_dataset(dataset, look_back=3):
    dataX, dataY = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back)]
        dataX.append(a)
        dataY.append(dataset[i + look_back])
    return np.array(dataX), np.array(dataY)
x, y = create_dataset(df_price['scale'])
print (x)
print (y.shape)
plt.subplots(figsize=(40,16))
plt.plot(y)
plt.title('Cel prognozowania')

size = int(len(x) * 0.75)

x_train, x_test = x[0:size], x[size:len(x)]
y_train, y_test = y[0:size], y[size:len(x)]
print ('x_train',x_train.shape, x_train[:5],y_train[:5])
print ('x_test',x_test.shape, x_test[:5],y_test[:5])

from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor
#clf = MLPRegressor(hidden_layer_sizes=(300,), activation = 'tanh',solver='adam', batch_size=32, max_iter=4000)
clf = MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,
               beta_2=0.999, early_stopping=False, epsilon=1e-08,
               hidden_layer_sizes=(50, 100, 50), learning_rate='constant',
               learning_rate_init=0.001, max_fun=15000, max_iter=5000,
               momentum=0.9, n_iter_no_change=200, nesterovs_momentum=True,
               power_t=0.5, random_state=None, shuffle=True, solver='adam',
               tol=0.0001, validation_fraction=0.1, verbose=True,
               warm_start=False)

clf.fit(x_train,y_train)

train_mse = clf.predict(x_train)
test_mse = clf.predict(x_test)
print ('MSE training', mean_squared_error(train_mse,y_train))
print ('MSE testing', mean_squared_error(test_mse,y_test))
train_pred = clf.predict(x_train)
test_pred = clf.predict(x_test)

plt.subplots(figsize=(40,16))
plt.plot(test_pred,label='Rezultat testowania')
plt.plot(y_test,color='red',label='Cel predykcji')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
plt.title('Testowanie')

plt.subplots(figsize=(40,16))
plt.plot(scaler.inverse_transform(train_pred.reshape(-1,1)),label='Rezultat treningu')
plt.plot(scaler.inverse_transform(y_train.reshape(-1,1)),color='red', label='Cel predykcji')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
plt.title('Rezultat treningu na rzeczywistych danych')

plt.subplots(figsize=(40,16))
plt.plot(scaler.inverse_transform(test_pred.reshape(-1,1)), label='Rezultat testowania')
plt.plot(scaler.inverse_transform(y_test.reshape(-1,1)),color='red',linewidth=0.75, label='Cel predykcji')
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
plt.title('Testowanie na rzeczywistych danych')

col_list = ["TS_UTC"]
df = pd.read_csv("rdn_csv.csv", sep=';', usecols=col_list)
df[['Data','Godzina']] = df.TS_UTC.str.split(" ",expand=True,)
df = df.drop(columns=['TS_UTC'])
df = df.drop(columns=['Data'])
df[['Godziny','Minuty']] = df.Godzina.str.split(":",expand=True,)
df = df.drop(columns=['Minuty'])
df = df.drop(columns=['Godzina'])
df = np.array(df).reshape(-1,1)
x_p = scaler.inverse_transform(test_pred.reshape(-1,1))
x_p = x_p[2:25]
x_y = scaler.inverse_transform(y_test.reshape(-1,1))
x_y = x_y[2:25]
godziny = df[2:25]
godziny = godziny.astype(float)
plt.subplots(figsize=(40,16))
plt.plot(godziny, x_p,color="blue")
plt.plot(x_y, color="red")

#Dobór parametrów modelu za pomocą Grid Search CV

import sklearn
from sklearn import metrics
from sklearn import neural_network
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import cross_validate

def mlp_model(X, Y):

  estimator=MLPRegressor()


  param_grid = {'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,1)],
            'activation': ['relu','tanh','logistic'],
            'alpha': [0.0001, 0.05],
            'learning_rate': ['constant','adaptive'],
            'solver': ['adam']}

  gsc = GridSearchCV(
      estimator,
      param_grid,
      cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)

  grid_result = gsc.fit(X, Y)


  best_params = grid_result.best_params_

  best_mlp = MLPRegressor(hidden_layer_sizes = best_params["hidden_layer_sizes"],
                          activation =best_params["activation"],
                          solver=best_params["solver"],
                          max_iter= 5000, n_iter_no_change = 200)

  scoring = {
            'abs_error': 'neg_mean_absolute_error',
            'squared_error': 'neg_mean_squared_error',
            'r2':'r2'}

  scores = cross_validate(best_mlp, X, Y, cv=10, scoring=scoring, return_train_score=True, return_estimator = True)
  return scores
mlp_model(x_train, y_train)